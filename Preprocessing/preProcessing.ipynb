{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f335bedf-7902-48a8-ab67-10588eb8b767",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# Author: Tongyue Sun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "855e9bc4-795f-4f96-8300-aa0dfa696e35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "# Note: The glob module should also be imported for wildcard matching\n",
    "import glob\n",
    "# Set the parent directory path\n",
    "parent_dir = '/target_output_dir'\n",
    "\n",
    "# Define a list of folder names to be created\n",
    "folders = ['Tissue_names_list_here']\n",
    "\n",
    "# Loop through each folder in the list\n",
    "for folder in folders:\n",
    "    # Construct the full path by joining the parent and current folder name\n",
    "    full_path = os.path.join(parent_dir, folder)\n",
    "    \n",
    "    # Create the directory if it doesn't exist (won't raise an error if already exists)\n",
    "    os.makedirs(full_path, exist_ok=True)\n",
    "\n",
    "# Define the paths for original data directory and target base directory (pseudo-code paths)\n",
    "original_data_dir = \"/original_data_path\"\n",
    "target_base_dir = \"/target_output_dir\"\n",
    "\n",
    "# Read TSV file and extract the first row (folder names) and second row (file stems)\n",
    "# The first row represents Tissue, and the second row indicates RAW Data ID. There is a one-to-one correspondence between each column of data.\n",
    "\n",
    "with open('data_ID_Tissues.tsv', 'r') as tsv_file:\n",
    "    lines = tsv_file.readlines()\n",
    "    folder_names = [name.strip() for name in lines[0].split('\\t')]\n",
    "    file_stems = [stem.strip() for stem in lines[1].split('\\t')]\n",
    "\n",
    "# Iterate over corresponding pairs of folder names and file stems\n",
    "for folder_name, file_stem in zip(folder_names, file_stems):\n",
    "    # Formulate the target folder path\n",
    "    target_folder = os.path.join(target_base_dir, folder_name)\n",
    "    \n",
    "    # Ensure that the target folder exists\n",
    "    if not os.path.exists(target_folder):\n",
    "        os.makedirs(target_folder)\n",
    "\n",
    "    # Construct the glob pattern to match all relevant source files\n",
    "    source_glob_pattern = os.path.join(original_data_dir, f\"{file_stem}_*.pat.gz*\")\n",
    "\n",
    "    # Find all matching files and copy them to the target folder\n",
    "    for src_file in glob.glob(source_glob_pattern):\n",
    "        # Get the destination file path within the target folder\n",
    "        dst_file = os.path.join(target_folder, os.path.basename(src_file))\n",
    "        \n",
    "        # Copy the source file to the destination\n",
    "        shutil.copy(src_file, dst_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293ee219-4af0-4031-8bd0-f98c95530d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy .beta files.\n",
    "for folder_name, file_stem in zip(folder_names, file_stems):\n",
    "    target_folder = os.path.join(target_base_dir, folder_name)\n",
    "    \n",
    "    if not os.path.exists(target_folder):\n",
    "        os.makedirs(target_folder)\n",
    "\n",
    "    source_glob_pattern = os.path.join(original_data_dir, f\"{file_stem}_*.beta\")\n",
    "    for src_file in glob.glob(source_glob_pattern):\n",
    "        dst_file = os.path.join(target_folder, os.path.basename(src_file))\n",
    "        shutil.copy(src_file, dst_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41befe7a-b2f1-4bc0-be56-da3334295a2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# Define the source and target directory paths to process\n",
    "root_dir = 'target directory paths'\n",
    "ref_dir_name = 'ref'\n",
    "mix_dir_name = 'mix'\n",
    "\n",
    "# Iterate through all folders representing different tissue types\n",
    "for folder in folders:\n",
    "    folder_path = os.path.join(root_dir, folder)\n",
    "    \n",
    "    # Ensure that the folder exists and contains at least two .pat.gz files\n",
    "    pat_files = [f for f in os.listdir(folder_path) if f.endswith('.pat.gz')]\n",
    "    csi_files = [f[:-7] + '.pat.gz.csi' for f in pat_files]\n",
    "    if len(pat_files) < 2:\n",
    "        print(f\"Folder '{folder}' does not have enough .pat.gz files.\")\n",
    "        continue\n",
    "    \n",
    "    # Create 'ref' and 'mix' subdirectories within the current folder\n",
    "    ref_subdir = os.path.join(folder_path, ref_dir_name)\n",
    "    mix_subdir = os.path.join(folder_path, mix_dir_name)\n",
    "    os.makedirs(ref_subdir, exist_ok=True)\n",
    "    os.makedirs(mix_subdir, exist_ok=True)\n",
    "\n",
    "    # For odd-numbered files, randomly select (odd_number - 1) pairs to move\n",
    "    num_to_move = len(pat_files) - (len(pat_files) % 2)\n",
    "    \n",
    "    # Randomly shuffle the files and evenly distribute them into 'ref' and 'mix' folders\n",
    "    random.shuffle(pat_files)\n",
    "    half_num = num_to_move // 2\n",
    "    ref_pat_files = pat_files[:half_num]\n",
    "    mix_pat_files = pat_files[half_num:num_to_move]\n",
    "    ref_csi_files = [f[:-7] + '.pat.gz.csi' for f in ref_pat_files]\n",
    "    mix_csi_files = [f[:-7] + '.pat.gz.csi' for f in mix_pat_files]\n",
    "\n",
    "    # Move file pairs (.pat.gz and .pat.gz.csi) to their respective directories\n",
    "    for pat_file, csi_file in zip(ref_pat_files, ref_csi_files):\n",
    "        src_pat = os.path.join(folder_path, pat_file)\n",
    "        dst_pat = os.path.join(ref_subdir, pat_file)\n",
    "        src_csi = os.path.join(folder_path, csi_file)\n",
    "        dst_csi = os.path.join(ref_subdir, csi_file)\n",
    "        shutil.move(src_pat, dst_pat)\n",
    "        shutil.move(src_csi, dst_csi)\n",
    "\n",
    "    for pat_file, csi_file in zip(mix_pat_files, mix_csi_files):\n",
    "        src_pat = os.path.join(folder_path, pat_file)\n",
    "        dst_pat = os.path.join(mix_subdir, pat_file)\n",
    "        src_csi = os.path.join(folder_path, csi_file)\n",
    "        dst_csi = os.path.join(mix_subdir, csi_file)\n",
    "        shutil.move(src_pat, dst_pat)\n",
    "        shutil.move(src_csi, dst_csi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881d1d74-93bd-4f1c-af66-26e2483f2275",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# The folder where the mixed data is finally stored.\n",
    "target_dir = 'Final folder'\n",
    "\n",
    "# Traverse through all folders of different tissue types\n",
    "for folder in folders:\n",
    "    ref_folder_path = os.path.join(root_dir, folder, 'ref')\n",
    "    mix_folder_path = os.path.join(root_dir, folder, 'mix')\n",
    "    ref_target_path = os.path.join(target_dir, 'ref', folder)\n",
    "    mix_target_path = os.path.join(target_dir, 'mix', folder)\n",
    "\n",
    "    if not os.path.exists(ref_folder_path) or not os.path.exists(mix_folder_path):\n",
    "        print(f\"Folder '{folder}' does not have both ref and mix subfolders.\")\n",
    "        continue\n",
    "    # The genome version used for the data.\n",
    "    assembly_version = 'hg38'\n",
    "    # Execute the merge command\n",
    "    ref_merge_cmd = f'wgbstools merge {ref_folder_path}/*.pat.gz --genome {assembly_version} -f -p {ref_target_path}'\n",
    "    subprocess.run(ref_merge_cmd, shell=True)\n",
    "\n",
    "    mix_merge_cmd = f'wgbstools merge {mix_folder_path}/*.pat.gz --genome {assembly_version} -f -p {mix_target_path}'\n",
    "    subprocess.run(mix_merge_cmd, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7f5160-4709-4aba-bdd6-a5e95bb513bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def run_cmd(cmd):\n",
    "    \"\"\"Run a shell command using `subprocess.run`.\"\"\"\n",
    "    subprocess.run(cmd, shell=True)\n",
    "\n",
    "input_directory = os.path.join(target_dir, 'mix')\n",
    "crd_output_directory = os.path.join(target_dir, 'crd_dis')\n",
    "matrix_filepath = os.path.join(target_dir, 'crd_dis.csv')\n",
    "\n",
    "# Get the sorted list of files in the input directory\n",
    "file_list = sorted(os.listdir(input_directory))\n",
    "file_list = [f for f in file_list if f.endswith(\".pat.gz\")]\n",
    "print(file_list)\n",
    "\n",
    "# Read the 'dirichlet_matrix_d.csv' file\n",
    "df = pd.read_csv(matrix_file)\n",
    "\n",
    "# Get the number of columns excluding the ID column\n",
    "num_columns = df.shape[1] - 1\n",
    "\n",
    "# Iterate through columns and execute commands concurrently\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    for col_index in range(1, num_columns + 1):\n",
    "        # Extract the data for the current column as a space-separated string\n",
    "        column_data = \" \".join(df.iloc[:, col_index].astype(str))\n",
    "\n",
    "        # Format the uniform parameter based on the column index\n",
    "        uniform_param = f\"crd_dis_{str(col_index).zfill(2)}\"  # Pad with zeros for consistent length\n",
    "\n",
    "        # Construct the mix_pat command\n",
    "        mix_pat_command = [\n",
    "            \"wgbstools\",\n",
    "            \"mix_pat\",\n",
    "            \" \".join([os.path.join(input_directory, f) for f in file_list]),\n",
    "            \"--rates\",\n",
    "            column_data,\n",
    "            \"-p\",\n",
    "            os.path.join(crd_output_directory, uniform_param),\n",
    "            \"--genome\",\n",
    "            \"hg38\",\n",
    "            \"-c\",\n",
    "            \"22\"\n",
    "        ]\n",
    "        \n",
    "        # Combine the command elements into a single string\n",
    "        mix_cmd_run = \" \".join(mix_pat_command)\n",
    "        print(f\"Executing command: {mix_cmd_run}\")\n",
    "\n",
    "        # Submit the command to be executed asynchronously\n",
    "        executor.submit(run_cmd, mix_cmd_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364d7368-fc25-42c9-816e-c0439a443fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cmd(cmd):\n",
    "    \"\"\"Run a shell command using `subprocess.run`.\"\"\"\n",
    "    subprocess.run(cmd, shell=True)\n",
    "\n",
    "input_directory = os.path.join(target_dir, 'mix')\n",
    "uniform_output_directory = os.path.join(target_dir, 'uniform_dis')\n",
    "matrix_filepath = os.path.join(target_dir, 'uniform_matrix.csv')\n",
    "\n",
    "# Get the sorted list of files in the input directory\n",
    "file_list = sorted(os.listdir(input_directory))\n",
    "file_list = [f for f in file_list if f.endswith(\".pat.gz\")]\n",
    "print(file_list)\n",
    "\n",
    "# Read the 'dirichlet_matrix_d.csv' file\n",
    "df = pd.read_csv(matrix_file)\n",
    "\n",
    "# Get the number of columns excluding the ID column\n",
    "num_columns = df.shape[1] - 1\n",
    "\n",
    "# Iterate through columns and execute commands concurrently\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    for col_index in range(1, num_columns + 1):\n",
    "        # Extract the data for the current column as a space-separated string\n",
    "        column_data = \" \".join(df.iloc[:, col_index].astype(str))\n",
    "\n",
    "        # Format the uniform parameter based on the column index\n",
    "        uniform_param = f\"uniform_dis_{str(col_index).zfill(2)}\"  # Pad with zeros for consistent length\n",
    "\n",
    "        # Construct the mix_pat command\n",
    "        mix_pat_command = [\n",
    "            \"wgbstools\",\n",
    "            \"mix_pat\",\n",
    "            \" \".join([os.path.join(input_directory, f) for f in file_list]),\n",
    "            \"--rates\",\n",
    "            column_data,\n",
    "            \"-p\",\n",
    "            os.path.join(uniform_output_directory, uniform_param),\n",
    "            \"--genome\",\n",
    "            \"hg38\",\n",
    "            \"-c\",\n",
    "            \"22\"\n",
    "        ]\n",
    "        \n",
    "        # Combine the command elements into a single string\n",
    "        mix_cmd_run = \" \".join(mix_pat_command)\n",
    "        print(f\"Executing command: {mix_cmd_run}\")\n",
    "\n",
    "        # Submit the command to be executed asynchronously\n",
    "        executor.submit(run_cmd, mix_cmd_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6f51c2-0eeb-4cdc-bfcc-33a727d9cdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate .beta files for each dataset(directory) \n",
    "assembly_version = 'hg38'\n",
    "# Execute the pat2beta command\n",
    "uniform_dis_cmd = f'wgbstools pat2beta {uniform_output_directory}/*.pat.gz --genome {assembly_version} -f -o {uniform_output_directory}/'\n",
    "subprocess.run(uniform_dis_cmd, shell=True)\n",
    "\n",
    "crd_dis_cmd = f'wgbstools pat2beta {crd_output_directory}/*.pat.gz --genome {assembly_version} -f -o {uniform_output_directory}/'\n",
    "subprocess.run(crd_dis_cmd, shell=True)\n",
    "\n",
    "ref_beta_cmd = f'wgbstools pat2beta {ref_folder_path}/*.pat.gz --genome {assembly_version} -f -o {ref_folder_path}/'\n",
    "subprocess.run(ref_beta_cmd, shell=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
