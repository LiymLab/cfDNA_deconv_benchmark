{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c347a7-71f3-4c55-a9b2-e53b6cfacc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating reference markers with different missing proportions by randomly introducing missingness. \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "\n",
    "# Define the array of median values\n",
    "median_values = np.concatenate([np.arange(15, 51, 5), np.arange(60, 101, 10)])\n",
    "\n",
    "# Loop through each median value\n",
    "for median in median_values:\n",
    "    # Create a directory for each specific median value\n",
    "    folder_path = f'ref_median_{median}/drop'\n",
    "\n",
    "    # Check if the directory exists; if not, create it\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "\n",
    "    # Iterate over various percentage drop situations\n",
    "    for percentage in [0.1, 0.2, 0.3, 0.4, 0.5]:\n",
    "        for k in range(20):\n",
    "            # Load the original data files\n",
    "            ref_file_path = f'ref_median_{median}/ref_depth_{median}_unique.csv'\n",
    "\n",
    "            # Read these files into Pandas DataFrames\n",
    "            ref_df = pd.read_csv(ref_file_path)\n",
    "\n",
    "            # Calculate the number of rows to randomly remove\n",
    "            num_rows_to_remove = int(len(ref_df) * percentage)\n",
    "            # Choose random indices to remove\n",
    "            indices_to_remove = random.sample(range(len(ref_df)), num_rows_to_remove)\n",
    "\n",
    "            # Remove the corresponding rows from both DataFrames\n",
    "            ref_df = ref_df.drop(indices_to_remove)\n",
    "\n",
    "            # Create and verify the existence of a subdirectory for storing modified files\n",
    "            drop_folder_path = f'ref_median_{median}/drop_{percentage}_col'\n",
    "            if not os.path.exists(drop_folder_path):\n",
    "                os.makedirs(drop_folder_path)\n",
    "\n",
    "            # Save the modified DataFrames to separate CSV files\n",
    "            ref_drop_file_path = f'{drop_folder_path}/reference_median_{median}_{k}.csv'\n",
    "\n",
    "            # Write DataFrames to disk without including the index\n",
    "            ref_df.to_csv(ref_drop_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cfd62e-1165-4df1-9aaa-54f02e801a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data for mixture under uniform distribution \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "\n",
    "# Define the range of median values\n",
    "median_values = np.concatenate([np.arange(15, 51, 5), np.arange(60, 101, 10)])\n",
    "\n",
    "# Loop through each median value\n",
    "for median in median_values:\n",
    "    # Create directory structure based on median value\n",
    "    folder_path = f'/cfDNA_benchmark/meth_atlas_data/uniform_dis/drop_col/ref_median_{median}'\n",
    "    \n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "\n",
    "    # Loop through different percentage drop scenarios\n",
    "    for percent in [0.1, 0.2, 0.3, 0.4, 0.5]:\n",
    "        drop_folder_path = f'{folder_path}/drop_{percent}_col'\n",
    "        \n",
    "        if not os.path.exists(drop_folder_path):\n",
    "            os.makedirs(drop_folder_path)\n",
    "            \n",
    "        # Set the path to the mixed dataset file\n",
    "        mix_file_path = f'/cfDNA_benchmark/meth_atlas_data/uniform_dis/uniform_mix/full_atlas_uniform_median_{median}.csv'\n",
    "\n",
    "        # Loop for k iterations\n",
    "        for k in range(20):\n",
    "            # Read original files\n",
    "            origin_drop_folder = f'/cfDNA_benchmark/meth_atlas_data/ref_median_{median}/drop_{percent}_col'\n",
    "            ref_drop_file_origin = f'{origin_drop_folder}/reference_median_{median}_{k}.csv'\n",
    "\n",
    "            ref_df = pd.read_csv(ref_drop_file_origin)\n",
    "            mix_df = pd.read_csv(mix_file_path)\n",
    "            \n",
    "            # Filter the mixed dataframe to keep rows where 'cpg_idx' is present in reference dataframe\n",
    "            mix_df = mix_df[mix_df['cpg_idx'].isin(ref_df['cpg_idx'])]\n",
    "            \n",
    "            # Ensure destination directory exists before saving\n",
    "            if not os.path.exists(drop_folder_path):\n",
    "                os.makedirs(drop_folder_path)\n",
    "\n",
    "            # Save processed reference and mixed dataframes\n",
    "            ref_drop_file_path = f'{drop_folder_path}/reference_median_{median}_{k}.csv'\n",
    "            mix_drop_file_path = f'{drop_folder_path}/fa_uniform_median_{median}_{k}.csv'\n",
    "\n",
    "            ref_df.to_csv(ref_drop_file_path, index=False)\n",
    "            mix_df.to_csv(mix_drop_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bedc78c-9456-4d29-9643-c6a1ba2124a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data for mixture under constrained random distribution (CRD)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "\n",
    "# Define the range of median values\n",
    "median_values = np.concatenate([np.arange(15, 51, 5), np.arange(60, 101, 10)])\n",
    "\n",
    "# Loop through each median value\n",
    "for median in median_values:\n",
    "    # Create directory structure based on median value\n",
    "    folder_path = f'/cfDNA_benchmark/meth_atlas_data/crd_dis/drop_col/ref_median_{median}'\n",
    "    \n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "\n",
    "    # Loop through different percentage drop scenarios\n",
    "    for percent in [0.1, 0.2, 0.3, 0.4, 0.5]:\n",
    "        drop_folder_path = f'{folder_path}/drop_{percent}_col'\n",
    "        \n",
    "        if not os.path.exists(drop_folder_path):\n",
    "            os.makedirs(drop_folder_path)\n",
    "            \n",
    "        # Set the path to the mixed dataset file\n",
    "        mix_file_path = f'/cfDNA_benchmark/meth_atlas_data/crd_dis/crd_mix/full_atlas_crd_median_{median}.csv'\n",
    "\n",
    "        # Loop for k iterations\n",
    "        for k in range(20):\n",
    "            # Read original files\n",
    "            origin_drop_folder = f'/cfDNA_benchmark/meth_atlas_data/ref_median_{median}/drop_{percent}_col'\n",
    "            ref_drop_file_origin = f'{origin_drop_folder}/reference_median_{median}_{k}.csv'\n",
    "\n",
    "            ref_df = pd.read_csv(ref_drop_file_origin)\n",
    "            mix_df = pd.read_csv(mix_file_path)\n",
    "            \n",
    "            # Filter the mixed dataframe to keep rows where 'cpg_idx' is present in reference dataframe\n",
    "            mix_df = mix_df[mix_df['cpg_idx'].isin(ref_df['cpg_idx'])]\n",
    "            \n",
    "            # Ensure destination directory exists before saving\n",
    "            if not os.path.exists(drop_folder_path):\n",
    "                os.makedirs(drop_folder_path)\n",
    "\n",
    "            # Save processed reference and mixed dataframes\n",
    "            ref_drop_file_path = f'{drop_folder_path}/reference_median_{median}_{k}.csv'\n",
    "            mix_drop_file_path = f'{drop_folder_path}/fa_crd_median_{median}_{k}.csv'\n",
    "\n",
    "            ref_df.to_csv(ref_drop_file_path, index=False)\n",
    "            mix_df.to_csv(mix_drop_file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
